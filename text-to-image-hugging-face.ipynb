{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shahjaysuhasbhai/text-to-image-hugging-face?scriptVersionId=273431552\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:12:38.319275Z","iopub.execute_input":"2025-11-04T12:12:38.319465Z","iopub.status.idle":"2025-11-04T12:12:40.364536Z","shell.execute_reply.started":"2025-11-04T12:12:38.319446Z","shell.execute_reply":"2025-11-04T12:12:40.363704Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:13:26.332634Z","iopub.execute_input":"2025-11-04T12:13:26.333543Z","iopub.status.idle":"2025-11-04T12:13:39.466617Z","shell.execute_reply.started":"2025-11-04T12:13:26.333472Z","shell.execute_reply":"2025-11-04T12:13:39.46571Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install diffusers transformers accelerate safetensors --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\nimport torch\nfrom PIL import Image # Python Imaging Library\n\n# Load model from Hugging Face\nmodel_id = \"runwayml/stable-diffusion-v1-5\"\n\npipe = StableDiffusionPipeline.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16 # tensors of 16bit floar number\n)\npipe = pipe.to(\"cuda\")       # Move model to GPU\npipe.enable_attention_slicing() # pipeline processes attention in smaller chunks instead of all at once\n# enable_attention_slicing requires expensive GPU computation\n\nprompt = \"a cute dog reading a book in a cozy library, digital art\"\n\nimage = pipe(prompt).images[0] # .images gives you the list of generated images so selecting first image\n# above line will\n# Tokenize the text, run the diffusion layer and generates img-output object\nimage.save(\"generated_image.png\")\nimage\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# With negative prompts which tells the model what we do not want in the img","metadata":{}},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\nimport torch\n\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-2-1\",\n    torch_dtype=torch.float16,\n    revision=\"fp16\",\n).to(\"cuda\")\n\nprompt = \"ultra detailed cinematic photo of a futuristic city skyline at sunset\"\nnegative_prompt = \"blurry, low quality, distorted, pixelated\"\n\nimage = pipe(\n    prompt=prompt,\n    negative_prompt=negative_prompt,\n    num_inference_steps=40,   # how many diffusion steps used to generate image.(40 to 50 ideally)\n    guidance_scale=7.5,       # how strongly the model follows your text prompt, 7â€“12 is good\n).images[0]\n\nimage.save(\"city_image.png\")\nimage\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}